{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "- One of basic supervised leaarning\n",
    "- Also called **lazy learning** or **Memory-based Learning** because in training phase, it just store the value of traning data -> ***Non-Parametric learning***\n",
    "- In predict phase, model will use difference type of distance metrics (distance measures):\n",
    "    + Euclidean\n",
    "    + Chebyshev\n",
    "    + Manhattan\n",
    "    + Minkowski\n",
    "- These distance metrics calculate the distance between the input and other values storing in the model, then ranking and finding **K** values have the nearest output. Finally, voting to find the output.\n",
    "![Alt text](resources/training_and_testing_1.png)\n",
    "\n",
    "- The KNN algorithm is widely used for classification and regression applications. \n",
    "![Alt text](resources/training_and_testing_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1D\n",
    "# Question 2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split train:test = 8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "iris_X,\n",
    "iris_y,\n",
    "test_size=0.2,\n",
    "random_state=42\n",
    ")\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Build KNN Classifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and Evaluate test set\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Paragraph A - Load the diabetes dataset \n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Paragraph D: Split train:test = 8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "diabetes_X,\n",
    "diabetes_y,\n",
    "test_size=0.2,\n",
    "random_state=42\n",
    ")\n",
    "\n",
    "# Paragraph B: Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Paragraph C: Build KNN model\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict and Evaluate test set\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7 - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load IMDB dataset\n",
    "imdb = load_dataset(\"imdb\")\n",
    "imdb_train, imdb_test = imdb['train'], imdb['test']\n",
    "\n",
    "# Convert text to vector using BoW\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X_train = vectorizer.fit_transform(imdb_train['text']).toarray()\n",
    "X_test = vectorizer.transform(imdb_test['text']).toarray()\n",
    "y_train = np.array(imdb_train['label'])\n",
    "y_test = np.array(imdb_test['label'])\n",
    "                            \n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build KNN Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree')\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict test set and evaluate\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Mean\n",
    "- K-Means is a popular clutering algorithm widely used in machine learning and data mining tasks. The goal of K-means is divide **n value points** into **k clusters** such that the points in the same cluster have the highest similarity.\n",
    "- The proccess of K-means including:\n",
    "    + **Initialization:** Randomly select ***k points*** from the dataset as the initial cluster centroids.\n",
    "    + **Assigment:** For each data point, calculate the distance from this point to all cluster centroids and assign it to the closet cluster. The distance is calculated by using ***Eucliddean distance***\n",
    "    + **Update centroids:** Update the centroid of each cluster by calculating the mean of the points in that cluster\n",
    "    + **Repeat**: Repeat the assignment and centroid update steps until the centroids no longer change or the change is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.array([\n",
    "    [2.0, 3.0, 1.5],\n",
    "    [3.0, 3.5, 2.0],\n",
    "    [3.5, 3.0, 2.5],\n",
    "    [7.5, 8.0, 7.5],\n",
    "    [8.5, 8.5, 8.0],\n",
    "    [9.0, 8.0, 8.5],\n",
    "    [1.0, 2.0, 1.0],\n",
    "    [1.5, 2.5, 1.5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k=3, max_iters=100):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.centroids = None\n",
    "        self.clusters = None\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        np.random.seed(42)\n",
    "        self.centroids = data[np.random.choice(data.shape[0], self.k, replace=False)]\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum(np.power(x1 - x2, 2)))\n",
    "\n",
    "    def assign_clusters(self, data):\n",
    "        distances = np.array([[self.euclidean_distance(x, centroid) for centroid in self.centroids] for x in data])\n",
    "        return np.argmin(distances, axis=1)\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        return np.array([data[self.clusters == i].mean(axis=0) for i in range(self.k)])\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.initialize_centroids(data)\n",
    "\n",
    "        for i in range(self.max_iters):\n",
    "            self.clusters = self.assign_clusters(data)\n",
    "\n",
    "            self.plot_clusters(data, i)\n",
    "\n",
    "            new_centroids = self.update_centroids(data)\n",
    "\n",
    "            if np.all(self.centroids == new_centroids):\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "        self.plot_final_clusters(data)\n",
    "\n",
    "    def plot_clusters(self, data, iteration):\n",
    "        plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)\n",
    "        plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')\n",
    "        plt.title(f\"Iteration {iteration + 1}\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_final_clusters(self, data):\n",
    "        plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)\n",
    "        plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')\n",
    "        plt.title(\"Final Clusters and Centroids\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=3)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8C\n",
    "# Question 9D\n",
    "# Question 10B\n",
    "# Question 11C\n",
    "# Question 12A\n",
    "# Question 13B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
